{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:16:40.903825Z",
     "start_time": "2023-08-26T08:16:39.935067Z"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import argparse\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from glob import glob\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split, GridSearchCV\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "# from impala.dbapi import connect\n",
    "# from impala.util import as_pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from functools import reduce\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step0. 데이터 수집 및 마트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:16:41.179991Z",
     "start_time": "2023-08-26T08:16:41.179985Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1) 공판장\n",
    "# nfbpsb.tmp_wmc_trn_inf_01\n",
    "# 경락단가, 상장수수료, 운송비, 하역비, kg당 판매금액 (평균)\n",
    "# 중량 (합계)\n",
    "\n",
    "# 2) 기상청\n",
    "# nfbpsb.tmp_weather_trn_inf_02\n",
    "\n",
    "# 3) 재고\n",
    "# nfbpsb.tmp_stpl_trn_inf_03\n",
    "# 차변수량, 매출수량, 재고수량 (합계)\n",
    "# 차변금액, 매출금액, 재고금액 (평균)\n",
    "\n",
    "# 4) 매입\n",
    "# nfbpsb.tmp_byng_trn_inf_04\n",
    "# 매입수량 (합계)\n",
    "# 매입금액 (평균)\n",
    "\n",
    "# 5) 소매\n",
    "# nfbpsb.tmp_retail_trn_inf_05\n",
    "# 소매가격 (평균)\n",
    "\n",
    "# 6) 도매시장 경락가격\n",
    "# nfbpsb.tmp_actopr_trn_inf_06\n",
    "# kg당 경락단가 (평균)\n",
    "\n",
    "# 7) 물가지수 (월별)\n",
    "# nfbpsb.tmp_prsix_trn_inf_07\n",
    "# 품목별 생산자물가지수, 품목성질별 생산자물가지수, 품목별 소비자물가지수, 품목성질별 소비자물가지수\n",
    "\n",
    "# 8) 동향지수 (월별)\n",
    "# nfbpsb.tmp_tnix_trn_inf_08\n",
    "# 현재생활형편CSI, 생활형편전망CSI, 향후경기전망CSI, 소비지출전망CSI, 외식비 지출전망CSI, 물가수준전망(1년후)CSI\n",
    "\n",
    "# 9) 수출입 (월별)\n",
    "# nfbpsb.tmp_imxp_trn_inf_09\n",
    "# 수입금액, 수출금액 (평균)\n",
    "# 수입중량, 수출중량 (합계)\n",
    "\n",
    "# 10) 하나로마트\n",
    "# nfbpsb.tmp_nacf_rtl_trn_inf_10\n",
    "# 순매출금액 (합계)\n",
    "\n",
    "#############################\n",
    "# 가락시장 경락가격\n",
    "\n",
    "# 출하량\n",
    "# nfbpsb.tmp_sl_trn_inf_00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1. Data Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:16:41.180753Z",
     "start_time": "2023-08-26T08:16:41.180747Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_df(df): #쿼리\n",
    "    sql = f\"\"\"SELECT * FROM \"\"\"+str(df)\n",
    "\n",
    "    con = connect(host = 'nhbpunloap01.nhbpad.nonghyup.com', port = '21050', \n",
    "                  kerberos_service_name = 'impala', use_ssl=False, auth_mechanism = 'GSSAPI')\n",
    "\n",
    "    impala_cursor = con.cursor() \n",
    "    impala_cursor.execute(sql) #쿼리 실행 \n",
    "    df = as_pandas(impala_cursor) #pandas 데이터 프레임으로 변경\n",
    "    \n",
    "    #byte 타입 변경\n",
    "    for col in df.columns:\n",
    "        if str(df[col][0])[0] == 'b':\n",
    "            df[col] = df[col].str.decode('utf-8')\n",
    "    impala_cursor.close()\n",
    "    con.close()\n",
    "    \n",
    "    return df\n",
    "\n",
    "#훈련 데이터 전체의 시작일 부터 마지막 일까지의 주차 생성\n",
    "def week_label(df):\n",
    "    \n",
    "    df['week_mark'] = np.nan\n",
    "    df['yyyy'] = df['yyyy'].astype('int')\n",
    "    year_range = int(max(df['yyyy'])) - int(min(df['yyyy']))+1\n",
    "    \n",
    "    for i in range(0,year_range*53):\n",
    "        min_mark = (datetime.strptime(min(df['bas_dt']), '%Y%m%d') + relativedelta(weeks=i)).strftime('%Y%m%d')\n",
    "        max_mark = (datetime.strptime(min(df['bas_dt']), '%Y%m%d') + relativedelta(weeks=i+1)).strftime('%Y%m%d')\n",
    "        \n",
    "        df.loc[(df['bas_dt']>=min_mark)&(df['bas_dt']<max_mark), 'week_mark'] = i\n",
    "    df['week_mark'] = df['week_mark'].astype(int)\n",
    "    df_prp = df.copy()\n",
    "    \n",
    "    return df_prp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가락시장 경락가격 전처리 (임시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:16:41.181656Z",
     "start_time": "2023-08-26T08:16:41.181652Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data Read\n",
    "garak_price = pd.read_csv('(가락시장)반입량및가격정보_201601_202307(최종).txt', encoding = 'UTF-8', sep = '\\t',\n",
    "                          dtype = {'품목':str, '구분':str, '단위':str})\n",
    "garak_price['도매 가격'] = garak_price['도매 가격'].str.replace(',','').astype(int)\n",
    "garak_price['반입량(누계)'] = garak_price['반입량(누계)'].str.replace(',','').astype(int)\n",
    "garak_price['반입량(평균)'] = garak_price['반입량(평균)'].str.replace(',','').astype(int)\n",
    "\n",
    "# 전처리\n",
    "garak_price = garak_price.loc[garak_price['품목명'].isin(['감자 수미', '대파', \n",
    "                                                         '사과 부사', '사과 아오리', '사과 홍로', '사과 양광',\n",
    "                                                         '무', '배추', '청양고추'])].reset_index(drop=True)\n",
    "garak_price = garak_price.loc[garak_price['단위'].str.contains('kg')].reset_index(drop = True)\n",
    "garak_price = garak_price.loc[garak_price['도매 가격'] != 0]\n",
    "garak_price = garak_price.loc[garak_price['반입량(누계)'] != 0]\n",
    "garak_price['단위(kg)'] = garak_price['단위'].str[:-2].astype(int)\n",
    "garak_price['kg당도매가'] = garak_price['도매 가격'].astype(int)/garak_price['단위(kg)']\n",
    "garak_price['반입량(kg)'] = garak_price['반입량(누계)']*garak_price['단위(kg)']\n",
    "garak_price['월'] = garak_price['구분'].str[:-3]\n",
    "\n",
    "garak_price_cleaned = garak_price[['품목명', '구분', '반입량(kg)', '도매 가격', 'kg당도매가']]\n",
    "garak_price_cleaned['품목명'] = garak_price_cleaned['품목명'].replace(to_replace = ['사과 부사', '사과 아오리', '사과 양광', '사과 홍로'], value = '사과')\n",
    "garak_price_cleaned['품목명'] = garak_price_cleaned['품목명'].replace(to_replace = ['감자 수미'], value = '감자')\n",
    "garak_price_cleaned['품목명'] = garak_price_cleaned['품목명'].replace(to_replace = ['청양고추'], value = '풋고추')\n",
    "garak_price_cleaned['구분'] = garak_price_cleaned['구분'].astype(str).str.replace('-','')\n",
    "garak_price_cleaned = garak_price_cleaned.rename({'품목명':'frpd_latcnm', '구분':'bas_dt', '반입량(kg)':'gk_mqt', 'kg당도매가':'gk_price'}, axis = 1)\n",
    "\n",
    "# 가격의 가중평균 구하기 (사과)\n",
    "grouped = garak_price_cleaned.groupby(['frpd_latcnm','bas_dt'])\n",
    "weighted_avg_func = lambda g:np.average(g['gk_price'], weights = g['gk_mqt'])\n",
    "garak_price_avg = grouped.apply(weighted_avg_func).to_frame(name = 'gk_price').reset_index()\n",
    "\n",
    "# 반입량 sum\n",
    "garak_kg_sum = garak_price_cleaned.pivot_table(values = 'gk_mqt', index = ['frpd_latcnm','bas_dt'], aggfunc = 'sum').reset_index()\n",
    "\n",
    "garak_price_avg = pd.merge(garak_price_avg, garak_kg_sum, on = ['frpd_latcnm','bas_dt'], how = 'outer')\n",
    "\n",
    "# garak_price_avg.to_csv('가락시장 도매가격.csv', encoding = 'utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기 & Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:16:41.182400Z",
     "start_time": "2023-08-26T08:16:41.182395Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 설명 변수\n",
    "# wmc = select_df('nfbpsb.tmp_wmc_trn_inf_01') #공판장\n",
    "# weather = select_df('nfbpsb.tmp_weather_trn_inf_02') #기상청\n",
    "# # null -> 0 전처리\n",
    "# weather = weather.fillna(0)\n",
    "# stpl = select_df('nfbpsb.tmp_stpl_trn_inf_03') #재고\n",
    "# byng = select_df('nfbpsb.tmp_byng_trn_inf_04') #매입\n",
    "# retail = select_df('nfbpsb.tmp_retail_trn_inf_05') #소매\n",
    "# actopr = select_df('nfbpsb.tmp_actopr_trn_inf_06') #도매시장 경락가격\n",
    "# prsix = select_df('nfbpsb.tmp_prsix_trn_inf_07') #물가지수(월별)\n",
    "# tnix = select_df('nfbpsb.tmp_tnix_trn_inf_08') #동향지수(월별)\n",
    "# imxp = select_df('nfbpsb.tmp_imxp_trn_inf_09') #수출입(월별) (풋고추 없음)\n",
    "# nacf_rtl = select_df('nfbpsb.tmp_nacf_rtl_trn_inf_10') #하나로마트\n",
    "\n",
    "# # 타겟 변수\n",
    "# # garak_price_avg #가락시장 가격\n",
    "# sl = select_df('nfbpsb.tmp_sl_trn_inf_00') #출하량 -> 2018년부터 존재 (가격 예측에 사용 X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:16:41.183194Z",
     "start_time": "2023-08-26T08:16:41.183189Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 일별 테이블 한번에 붙이기\n",
    "# datasets = [wmc, stpl, byng, retail, actopr, nacf_rtl]\n",
    "# df = reduce(lambda left, right: pd.merge(left, right, on = ['frpd_latcnm', 'bas_dt', 'bas_week'],\n",
    "#                                          how = 'outer'), datasets)\n",
    "# # 기상 테이블 join\n",
    "# df = pd.merge(df, weather, on = ['bas_dt', 'bas_week'], how = 'outer')\n",
    "\n",
    "# # 월별 테이블 붙이기 (월별테이블은 월 말에 적재되는 이유로 전월 데이터만 사용 예정)\n",
    "# df['bas_dt'] = pd.to_datetime(df['bas_dt'])\n",
    "# df['bas_ym'] = df['bas_dt'].dt.to_period('M')\n",
    "# df['bas_ym'] = df['bas_ym'].dt.strftime('%Y%m')\n",
    "# df['bas_dt'] = df['bas_dt'].dt.strftime('%Y%m%d')\n",
    "# datasets = [df, prsix, imxp]\n",
    "# df = reduce(lambda left, right: pd.merge(left, right, on = ['frpd_latcnm', 'bas_ym'],\n",
    "#                                          how = 'outer'), datasets)\n",
    "# df = pd.merge(df, tnix, on = 'bas_ym', how = 'outer')\n",
    "\n",
    "# # 가락시장 가격 테이블에 left join\n",
    "# df = pd.merge(garak_price_avg, df, on = ['frpd_latcnm', 'bas_dt'], how = 'left')\n",
    "\n",
    "# # 요일, 년도, 월, 일, 주차 생성\n",
    "# df['bas_dt'] = pd.to_datetime(df['bas_dt'])\n",
    "# df['weekday'] = df['bas_dt'].dt.day_name()\n",
    "# df['yyyy'] = df['bas_dt'].dt.year\n",
    "# df['mm'] = df['bas_dt'].dt.month\n",
    "# df['dd'] = df['bas_dt'].dt.day\n",
    "# df['week'] = df['bas_week'].str[4:].astype(int)\n",
    "# df['bas_dt'] = df['bas_dt'].dt.strftime('%Y%m%d')\n",
    "\n",
    "# drop_idx = df.loc[df['weekday']=='Sunday'].index #일요일 삭제\n",
    "# df.drop(drop_idx, inplace=True)\n",
    "\n",
    "# # 요일 컬럼 더미변수화\n",
    "# weekday_dummies = pd.get_dummies(df['weekday'])\n",
    "# df = pd.concat([df, weekday_dummies], axis = 1)\n",
    "\n",
    "# # 훈련 데이터 전체의 시작일 부터 마지막 일까지의 주차 생성\n",
    "# df = week_label(df)\n",
    "\n",
    "# df = df.sort_values(['frpd_latcnm', 'bas_dt']).reset_index(drop = True)\n",
    "\n",
    "# ##################################################################################################################\n",
    "# # 가격데이터 들어올 때 까지 (임시)\n",
    "# df = df.loc[(df['bas_dt'] >= '20160101') & (df['bas_dt'] <= '20230731')]\n",
    "\n",
    "# df = df[['frpd_latcnm', 'bas_dt', 'bas_ym', 'bas_week', 'yyyy', 'mm', 'dd', 'week', 'weekday', 'week_mark',\n",
    "#          'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday',\n",
    "#          'gk_price', 'gk_mqt', 'acto_upr', 'lstg_fee', 'trpcs', 'stvcs',\n",
    "#          'wt', 'sel_am', 'db_wt', 'db_am', 'sl_wt', 'slam', 'stpl_wt', 'stpl_am',\n",
    "#          'byng_mqt', 'byam', 'price', 'tot_qty', 'whsl_acto_trqt', 'nslam',\n",
    "#          'avgta_south', 'minta_south', 'maxta_south', 'sumrndur_south', 'sumrn_south', 'maxws_south',\n",
    "#          'avgws_south', 'avgtd_south', 'minrhm_south', 'avgrhm_south', 'avgpv_south', 'avgpa_south',\n",
    "#          'maxps_south', 'minps_south', 'avgps_south', 'ssdur_south', 'sumsshr_south', 'sumgsr_south',\n",
    "#          'ddmes_south', 'avgtca_south', 'avgts_south', 'mintg_south', 'sumfogdur_south',\n",
    "#          'avgta_mid', 'minta_mid', 'maxta_mid', 'sumrndur_mid', 'sumrn_mid', 'maxws_mid',\n",
    "#          'avgws_mid', 'avgtd_mid', 'minrhm_mid', 'avgrhm_mid', 'avgpv_mid', 'avgpa_mid',\n",
    "#          'maxps_mid', 'minps_mid', 'avgps_mid', 'ssdur_mid', 'sumsshr_mid', 'sumgsr_mid',\n",
    "#          'ddmes_mid', 'avgtca_mid', 'avgts_mid', 'mintg_mid', 'sumfogdur_mid',\n",
    "#          'lact_pdmn_prs_ix', 'lact_chr_pdmn_prs_ix', 'lact_csmr_prs_ix', 'lact_chr_csmr_prs_ix',\n",
    "#          'expdlr', 'expwgt', 'impdlr', 'impwgt', 'now_lfe_sts_csi', 'lfe_sts_viw_csi',\n",
    "#          'haf_dwtn_viw_csi', 'csm_xps_viw_csi', 'dinotcst_xps_viw_csi', 'prslvl_viw_csi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:16:41.184238Z",
     "start_time": "2023-08-26T08:16:41.184234Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.to_csv('datasets_merged_가격.csv', encoding = 'utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 품목별 DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:16:44.462536Z",
     "start_time": "2023-08-26T08:16:44.359161Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets_merged_가격.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:16:45.005151Z",
     "start_time": "2023-08-26T08:16:44.995992Z"
    }
   },
   "outputs": [],
   "source": [
    "def df_preprocess(datasets, frpd_latcnm):\n",
    "    \n",
    "    df = datasets.loc[datasets['frpd_latcnm'] == frpd_latcnm].drop(['frpd_latcnm'], axis = 1)\n",
    "    \n",
    "    # 1) 가격변수/물량변수/기상변수(강수계속시간, 일강수량, 안개계속시간) \n",
    "    # 주평균 -> 월평균\n",
    "    # 날짜 제외한 모든 변수 데이터 타입 변경\n",
    "    cols_date = ['frpd_latcnm', 'bas_dt', 'bas_ym', 'bas_week', 'yyyy', 'mm', 'dd', 'week', 'weekday', 'week_mark',\n",
    "                 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "    cols_all = [col for col in list(df.columns) if col not in cols_date]\n",
    "    for col in cols_all:\n",
    "        df[col] = df[col].astype(float)\n",
    "    col_am_mqt = ['gk_price', 'gk_mqt', 'acto_upr', 'lstg_fee', 'trpcs', 'stvcs', 'wt', \n",
    "                  'sel_am', 'db_wt', 'db_am', 'sl_wt', 'slam', 'stpl_wt', 'stpl_am',\n",
    "                  'byng_mqt', 'byam', 'price', 'tot_qty', 'whsl_acto_trqt', 'nslam']\n",
    "    col_weather = ['sumrndur_south', 'sumrndur_mid', 'sumrn_south', 'sumrn_mid', 'sumfogdur_south', 'sumfogdur_mid']\n",
    "    column_to_fill = col_am_mqt + col_weather\n",
    "\n",
    "    # 주 평균으로 채우기\n",
    "    weekly_avg = df.groupby(['bas_week'])[column_to_fill].transform('mean')\n",
    "    df[column_to_fill].fillna(weekly_avg, inplace = True)\n",
    "\n",
    "    # 월 평균으로 채우기 (주 평균으로 null값 채워지지 않을경우 대비)\n",
    "    monthly_avg = df.groupby(['bas_ym'])[column_to_fill].transform('mean')\n",
    "    df[column_to_fill].fillna(monthly_avg, inplace = True)\n",
    "\n",
    "    # 2) 나머지 변수 -> ffill/bfill\n",
    "    df = df.fillna(method = 'ffill').fillna(method = 'bfill')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:16:46.492061Z",
     "start_time": "2023-08-26T08:16:46.393079Z"
    }
   },
   "outputs": [],
   "source": [
    "df_potato = df_preprocess(df, '감자')\n",
    "df_leak = df_preprocess(df, '대파')\n",
    "df_radish = df_preprocess(df, '무')\n",
    "df_cabbage = df_preprocess(df, '배추')\n",
    "df_apple = df_preprocess(df, '사과')\n",
    "df_pepper = df_preprocess(df, '풋고추')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:16:53.214762Z",
     "start_time": "2023-08-26T08:16:53.208296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2306, 95)\n",
      "(2248, 95)\n",
      "(2304, 95)\n",
      "(2308, 95)\n",
      "(2266, 95)\n",
      "(2294, 95)\n"
     ]
    }
   ],
   "source": [
    "print(df_potato.shape)\n",
    "print(df_leak.shape)\n",
    "print(df_radish.shape)\n",
    "print(df_cabbage.shape)\n",
    "print(df_apple.shape)\n",
    "print(df_pepper.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2. 파생변수 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시차변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:16:56.614670Z",
     "start_time": "2023-08-26T08:16:56.600913Z"
    }
   },
   "outputs": [],
   "source": [
    "# 시차변수 생성\n",
    "def lag_variable(df, y_col, col_type):\n",
    "    \n",
    "    if col_type == 'target':\n",
    "        # 1일 ~ 24일 후 값\n",
    "        for day in range(1, 25):\n",
    "            df[y_col+'_'+str(day)+'day_after'] = df[y_col].shift(-day)\n",
    "    \n",
    "    if col_type == 'day':\n",
    "        # 1일 전 값\n",
    "        day_ls = [1]\n",
    "        for day in day_ls:\n",
    "            df[y_col+'_'+str(day)+'day_ago'] = df[y_col].shift(day)\n",
    "\n",
    "        # 1주, 4주 전 값\n",
    "        week_ls = [1,4]\n",
    "        for week in week_ls:\n",
    "            df[y_col+'_'+str(week)+'wk_ago'] = df.apply(lambda row: df[(df['week_mark'] == row['week_mark'] - week) \n",
    "                                                                  & (df['weekday'] == row['weekday'])][y_col].mean(), axis = 1)\n",
    "\n",
    "        # 지난 3/5/7/15일간 평균\n",
    "        day_ls = [3,5,7,15]\n",
    "        for day in day_ls:\n",
    "            df[y_col+'_'+str(day)+'day_avg'] = df[y_col].rolling(window=day).mean()\n",
    "\n",
    "        # 1년 전 동일 월 평균\n",
    "        year_ls = [1]\n",
    "        for year in year_ls:\n",
    "            df[y_col+'_'+str(year)+'ym_avg'] = df.apply(lambda row: df[(df['yyyy'] == row['yyyy'] - year) \n",
    "                                                                  & (df['mm'] == row['mm'])][y_col].mean(), axis = 1)\n",
    "\n",
    "        # 1년 전 동일 주차 평균\n",
    "        year_ls = [1]\n",
    "        for year in year_ls:\n",
    "            df[y_col+'_'+str(year)+'yw_avg'] = df.apply(lambda row: df[(df['week_mark'] == row['week_mark'] - 52) \n",
    "                                                                      ][y_col].mean(), axis = 1)\n",
    "            \n",
    "    if col_type == 'month':\n",
    "        # 1월 전\n",
    "        month_ls = [1]\n",
    "        for month in month_ls:\n",
    "            df[y_col+'_'+str(month)+'month_ago'] = df.apply(lambda row: df[(df['bas_ym'] == (pd.to_datetime(row['bas_dt']) - relativedelta(months = month)).strftime('%Y%m'))\n",
    "                                                                          ][y_col].mean(), axis = 1)\n",
    "        \n",
    "        # 1년 전 동일 월 평균\n",
    "        year_ls = [1]\n",
    "        for year in year_ls:\n",
    "            df[y_col+'_'+str(year)+'ym_avg'] = df.apply(lambda row: df[(df['yyyy'] == row['yyyy'] - year) \n",
    "                                                                  & (df['mm'] == row['mm'])][y_col].mean(), axis = 1)\n",
    "    \n",
    "    df.reset_index(drop = True, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:27:18.682880Z",
     "start_time": "2023-08-26T08:16:57.599426Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_potato 실행시간: 104.91838884353638초\n",
      "df_leak 실행시간: 101.28769207000732초\n",
      "df_radish 실행시간: 102.7426393032074초\n",
      "df_cabbage 실행시간: 105.28370118141174초\n",
      "df_apple 실행시간: 102.84782314300537초\n",
      "df_pepper 실행시간: 103.99173378944397초\n"
     ]
    }
   ],
   "source": [
    "# 모든 변수\n",
    "cols_date = ['frpd_latcnm', 'bas_dt', 'bas_ym', 'bas_week', 'yyyy', 'mm', 'dd', 'week', 'weekday', 'week_mark',\n",
    "             'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "cols_all = [col for col in list(df.columns) if col not in cols_date]\n",
    "# 월별 변수\n",
    "cols_month = ['lact_pdmn_prs_ix', 'lact_chr_pdmn_prs_ix', 'lact_csmr_prs_ix', 'lact_chr_csmr_prs_ix',\n",
    "              'expdlr', 'expwgt', 'impdlr', 'impwgt', 'now_lfe_sts_csi', 'lfe_sts_viw_csi', \n",
    "              'haf_dwtn_viw_csi', 'csm_xps_viw_csi', 'dinotcst_xps_viw_csi', 'prslvl_viw_csi']\n",
    "# 일별 변수\n",
    "cols_day = [col for col in cols_all if col not in cols_month]\n",
    "########################################################################################################################\n",
    "\n",
    "df_all = {'df_potato':df_potato, 'df_leak':df_leak, 'df_radish':df_radish,\n",
    "          'df_cabbage':df_cabbage, 'df_apple':df_apple, 'df_pepper':df_pepper}\n",
    "df_all_preprocessed = []\n",
    "for key, value in df_all.items():\n",
    "    start_time = time.time()\n",
    "    # 시차변수 생성을 위한 dataframe\n",
    "    df_lag = value.copy()\n",
    "\n",
    "    # 시차변수 생성 (일/월)\n",
    "    # 일별컬럼\n",
    "    for col in cols_day:\n",
    "        df_lag = lag_variable(df_lag, col, 'day')\n",
    "    \n",
    "    # 월별컬럼\n",
    "    for col in cols_month:\n",
    "        df_lag = lag_variable(df_lag, col, 'month')\n",
    "        \n",
    "    # 타겟 변수\n",
    "    df_lag = lag_variable(df_lag, 'gk_price', 'target')\n",
    "    \n",
    "    # 전년동월/주차 시차변수를 생성할 수 없는 값들을 drop\n",
    "    # 2016년~ 데이터를 생성한 뒤 2017년 데이터부터 사용하는 방법\n",
    "    df_lag = df_lag.loc[df_lag['yyyy'] != 2016].reset_index(drop = True)\n",
    "    \n",
    "    # 당월변수 삭제 (월별테이블은 월 말에 적재되는 이유로 전월 데이터만 사용 예정)\n",
    "    df_lag.drop(cols_month, axis = 1, inplace = True)\n",
    "    \n",
    "    # null값 전처리\n",
    "    df_lag = df_lag.fillna(method = 'ffill').fillna(method = 'bfill')\n",
    "\n",
    "    df_all_preprocessed.append(df_lag)\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"{key} 실행시간: {execution_time}초\")\n",
    "    \n",
    "df_potato = df_all_preprocessed[0]\n",
    "df_leak = df_all_preprocessed[1]\n",
    "df_radish = df_all_preprocessed[2]\n",
    "df_cabbage = df_all_preprocessed[3]\n",
    "df_apple = df_all_preprocessed[4]\n",
    "df_pepper = df_all_preprocessed[5]\n",
    "\n",
    "# 풋고추 - 수출입 변수가 없음\n",
    "df_pepper.drop(['expdlr_1month_ago', 'expdlr_1ym_avg','expwgt_1month_ago','expwgt_1ym_avg',\n",
    "                'impdlr_1month_ago','impdlr_1ym_avg','impwgt_1month_ago','impwgt_1ym_avg'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:29:10.144716Z",
     "start_time": "2023-08-26T08:29:10.140516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2003, 727)\n",
      "(1961, 727)\n",
      "(2001, 727)\n",
      "(2005, 727)\n",
      "(1972, 727)\n",
      "(2007, 719)\n"
     ]
    }
   ],
   "source": [
    "print(df_potato.shape)\n",
    "print(df_leak.shape)\n",
    "print(df_radish.shape)\n",
    "print(df_cabbage.shape)\n",
    "print(df_apple.shape)\n",
    "print(df_pepper.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:29:17.259013Z",
     "start_time": "2023-08-26T08:29:14.016919Z"
    }
   },
   "outputs": [],
   "source": [
    "df_potato.to_csv('price_potato.csv', encoding = 'utf-8', index=False)\n",
    "df_leak.to_csv('price_leak.csv', encoding = 'utf-8', index=False)\n",
    "df_radish.to_csv('price_radish.csv', encoding = 'utf-8', index=False)\n",
    "df_cabbage.to_csv('price_cabbage.csv', encoding = 'utf-8', index=False)\n",
    "df_apple.to_csv('price_apple.csv', encoding = 'utf-8', index=False)\n",
    "df_pepper.to_csv('price_pepper.csv', encoding = 'utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3. Variable Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수 중요도 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:30:00.920980Z",
     "start_time": "2023-08-26T08:30:00.348588Z"
    }
   },
   "outputs": [],
   "source": [
    "df_potato = pd.read_csv('price_potato.csv')\n",
    "df_leak = pd.read_csv('price_leak.csv')\n",
    "df_radish = pd.read_csv('price_radish.csv')\n",
    "df_cabbage = pd.read_csv('price_cabbage.csv')\n",
    "df_apple = pd.read_csv('price_apple.csv')\n",
    "df_pepper = pd.read_csv('price_pepper.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:30:11.839901Z",
     "start_time": "2023-08-26T08:30:11.835729Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_pk = ['bas_dt', 'bas_ym', 'bas_week', 'yyyy', 'mm', 'dd', 'week', 'weekday', 'week_mark']\n",
    "\n",
    "cols_date = ['bas_dt', 'bas_ym', 'bas_week', 'yyyy', 'mm', 'dd', 'week', 'weekday', 'week_mark',\n",
    "             'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "\n",
    "cols_target = ['gk_price_1day_after', 'gk_price_2day_after', 'gk_price_3day_after', 'gk_price_4day_after', \n",
    "               'gk_price_5day_after', 'gk_price_6day_after', 'gk_price_7day_after', 'gk_price_8day_after',\n",
    "               'gk_price_9day_after', 'gk_price_10day_after', 'gk_price_11day_after', 'gk_price_12day_after',\n",
    "               'gk_price_13day_after', 'gk_price_14day_after', 'gk_price_15day_after', 'gk_price_16day_after',\n",
    "               'gk_price_17day_after', 'gk_price_18day_after', 'gk_price_19day_after', 'gk_price_20day_after',\n",
    "               'gk_price_21day_after', 'gk_price_22day_after', 'gk_price_23day_after', 'gk_price_24day_after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:30:12.717762Z",
     "start_time": "2023-08-26T08:30:12.713202Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def analyze_regression(X, y):\n",
    "    # 회귀분석 수행\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    p_values = model.pvalues[1:]\n",
    "    coef_abs = np.abs(model.params[1:])\n",
    "    return p_values, coef_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price_potato 실행시간: 5.765171051025391초\n",
      "price_leak 실행시간: 5.641207218170166초\n",
      "price_radish 실행시간: 5.610416412353516초\n",
      "price_cabbage 실행시간: 5.658376455307007초\n",
      "price_apple 실행시간: 5.598175048828125초\n",
      "price_pepper 실행시간: 5.614177465438843초\n"
     ]
    }
   ],
   "source": [
    "df_all = {'price_potato':df_potato, 'price_leak':df_leak, 'price_radish':df_radish,\n",
    "          'price_cabbage':df_cabbage, 'price_apple':df_apple, 'price_pepper':df_pepper}\n",
    "\n",
    "importance_xgb_all = []\n",
    "importance_reg_all = []\n",
    "\n",
    "for key, value in df_all.items():\n",
    "    df_tmp = value.copy()\n",
    "    \n",
    "    df_tmp = df_tmp.drop(cols_pk, axis = 1)\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    X = df_tmp.drop(cols_target, axis = 1)\n",
    "    Y = df_tmp['gk_price_1day_after']\n",
    "\n",
    "    # XGBoost Regressor\n",
    "    model = XGBRegressor(objective = 'reg:squarederror', n_estimators=100, random_state=42)\n",
    "    model.fit(X, Y)\n",
    "\n",
    "    importances_xgb = model.feature_importances_\n",
    "\n",
    "    importance_xgb_df = pd.DataFrame({'Feature':X.columns, 'Importance':importances_xgb})\n",
    "    importance_xgb_df = importance_xgb_df.sort_values(by = 'Importance', ascending = False).reset_index(drop=True)\n",
    "    \n",
    "    importance_xgb_all.append(importance_xgb_df)\n",
    "    \n",
    "    # Linear Regression\n",
    "    p_values, coef_abs = analyze_regression(X, Y)\n",
    "    \n",
    "    variable_importance = dict(zip(X.columns, coef_abs))\n",
    "\n",
    "    importance_reg_df = pd.DataFrame({\n",
    "        'Columns': list(variable_importance.keys()),\n",
    "        'p_value': p_values,\n",
    "        'Importance': coef_abs\n",
    "    })\n",
    "    importance_reg_df = importance_reg_df[importance_reg_df['p_value'] < 0.05] # 유의한 변수만\n",
    "    importance_reg_df = importance_reg_df.sort_values(by = 'Importance', ascending = False).reset_index(drop=True)\n",
    "    \n",
    "    importance_reg_all.append(importance_reg_df)\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"{key} 실행시간: {execution_time}초\")\n",
    "    \n",
    "#     filename_xgb = f\"{key}_importance_xgb.csv\"\n",
    "#     importance_xgb_df.to_csv(filename_xgb, encoding = 'utf-8', index=False)\n",
    "    \n",
    "#     filename_reg = f\"{key}_importance_reg.csv\"\n",
    "#     importance_reg_df.to_csv(filename_reg, encoding = 'utf-8', index=False)\n",
    "    \n",
    "# XGBoost Regressor\n",
    "xgb_potato = importance_xgb_all[0]\n",
    "xgb_leak = importance_xgb_all[1]\n",
    "xgb_radish = importance_xgb_all[2]\n",
    "xgb_cabbage = importance_xgb_all[3]\n",
    "xgb_apple = importance_xgb_all[4]\n",
    "xgb_pepper = importance_xgb_all[5]\n",
    "\n",
    "# Linear Regression\n",
    "reg_potato = importance_reg_all[0]\n",
    "reg_leak = importance_reg_all[1]\n",
    "reg_radish = importance_reg_all[2]\n",
    "reg_cabbage = importance_reg_all[3]\n",
    "reg_apple = importance_reg_all[4]\n",
    "reg_pepper = importance_reg_all[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4. Model 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sample_same_week(df, column_name):\n",
    "    unique_weeks = df[column_name].unique()\n",
    "    sampled_rows = []\n",
    "    \n",
    "    for week in unique_weeks:\n",
    "        week_rows = df[df[column_name] == week]\n",
    "        sampled_row = week_rows.sample(n = 1, random_state = 42)\n",
    "        sampled_rows.append(sampled_row)\n",
    "    \n",
    "    result_df = pd.concat(sampled_rows)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter colsample_bytree for estimator RandomForestRegressor(). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-131de434ab70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;31m# 최적의 하이퍼파라미터\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best Parameters:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 715\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_params\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnested_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0mvalid_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msub_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    250\u001b[0m                                  \u001b[0;34m'Check the list of available parameters '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                                  \u001b[0;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                                  (key, self))\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdelim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter colsample_bytree for estimator RandomForestRegressor(). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "df_all = {'price_potato':df_potato, 'price_leak':df_leak, 'price_radish':df_radish,\n",
    "          'price_cabbage':df_cabbage, 'price_apple':df_apple, 'price_pepper':df_pepper}\n",
    "# 성능지표 저장\n",
    "eval_df_all = []\n",
    "# 변수 중요도 저장\n",
    "importance_df_all = []\n",
    "# 결과 저장\n",
    "results_all = []\n",
    "\n",
    "for key, value in df_all.items():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if key == 'price_potato': frpd_latcnm = '감자'\n",
    "    if key == 'price_leak': frpd_latcnm = '대파'\n",
    "    if key == 'price_radish': frpd_latcnm = '무'\n",
    "    if key == 'price_cabbage': frpd_latcnm = '배추'\n",
    "    if key == 'price_apple': frpd_latcnm = '사과'\n",
    "    if key == 'price_pepper': frpd_latcnm = '풋고추'\n",
    "    \n",
    "    df_tmp = value.copy()\n",
    "    \n",
    "    ##############################################################################\n",
    "    ## Variable Selection\n",
    "    df_tmp = df_tmp.drop(cols_pk, axis = 1)\n",
    "    X = df_tmp.drop(cols_target, axis = 1)\n",
    "    Y = df_tmp['gk_price_1day_after']\n",
    "\n",
    "    model = XGBRegressor(objective = 'reg:squarederror', n_estimators=100, random_state=42)\n",
    "    model.fit(X, Y)\n",
    "\n",
    "    importances_xgb = model.feature_importances_\n",
    "\n",
    "    importance_xgb_df = pd.DataFrame({'Feature':X.columns, 'Importance':importances_xgb})\n",
    "    importance_xgb_df = importance_xgb_df.sort_values(by = 'Importance', ascending = False).reset_index(drop=True)\n",
    "    \n",
    "    ##############################################################################\n",
    "    df_tmp = value.copy()\n",
    "    \n",
    "    # TOP100 변수 선택\n",
    "    cols_selected = list(importance_xgb_df['Feature'].head(100)) #변수 개수 지정\n",
    "    cols_model = cols_pk + cols_target + cols_selected\n",
    "    df_tmp = df_tmp[cols_model]\n",
    "\n",
    "    # 가격 데이터가 모두 있는 20230701까지의 데이터 사용 (임시)\n",
    "    df_tmp['bas_dt'] = df_tmp['bas_dt'].astype(str)\n",
    "    train_tmp = df_tmp.loc[(df_tmp['bas_dt'] >= '20210701') & (df_tmp['bas_dt'] <= '20220703')]\n",
    "    test_tmp = df_tmp.loc[(df_tmp['bas_dt'] >= '20220704') & (df_tmp['bas_dt'] <= '20230701')]\n",
    "    \n",
    "    # 주별로 하나의 값만 random sampling\n",
    "    test_sampled = random_sample_same_week(test_tmp, 'bas_week')\n",
    "    # 나머지 row들은 학습에 사용\n",
    "    remaining_indices = list(set(test_tmp.index) - set(test_sampled.index))\n",
    "    remaining_test = test_tmp.loc[remaining_indices].reset_index(drop = True)\n",
    "    train_tmp = pd.concat([train_tmp, remaining_test], ignore_index = True)\n",
    "\n",
    "    test_tmp = test_sampled.copy()\n",
    "\n",
    "    train_data = train_tmp.drop(cols_pk, axis = 1)\n",
    "    test_data = test_tmp.drop(cols_pk, axis = 1)\n",
    "    \n",
    "    ## cols_target\n",
    "    # 훈련 데이터셋 생성\n",
    "    X_train = train_data.drop(cols_target, axis = 1)\n",
    "    y_train = train_data[cols_target]\n",
    "\n",
    "    # 테스트 데이터셋 생성\n",
    "    X_test = test_data.drop(cols_target, axis = 1)\n",
    "    y_test = test_data[cols_target]\n",
    "        \n",
    "    ##############################################################################\n",
    "    # TimeSeriesSplit 객체 생성\n",
    "    tscv = TimeSeriesSplit(n_splits = 5)\n",
    "\n",
    "    # hyperparameter 그리드 정의\n",
    "    param_grid = {\n",
    "        'estimator__n_estimators': [100, 200, 300],\n",
    "        'estimator__max_depth': [3, 4, 5],\n",
    "        'estimator__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'estimator__colsample_bytree':[0.3, 0.7, 1.0]\n",
    "        }\n",
    "\n",
    "    # Grid Search 객체 생성\n",
    "    grid_search = GridSearchCV(\n",
    "        MultiOutputRegressor(XGBRegressor(objective = 'reg:squarederror')), \n",
    "        param_grid = param_grid, \n",
    "        scoring = 'neg_mean_absolute_error', # 평가지표\n",
    "        cv = tscv # TimeSeriesSplit\n",
    "        )\n",
    "\n",
    "    # 최적의 하이퍼파라미터\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    ##############################################################################\n",
    "    \n",
    "#     # 저장된 모델 불러오기\n",
    "#     model_name = f\"{key}_model.pkl\"\n",
    "#     with open(model_name, 'rb') as f:\n",
    "#         best_model = pickle.load(f)\n",
    "\n",
    "    # 예측\n",
    "    test_preds = best_model.predict(X_test)\n",
    "\n",
    "    ##############################################################################\n",
    "    # Test 성능\n",
    "    mse = mean_squared_error(y_test, test_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, test_preds)\n",
    "    mape = mean_absolute_percentage_error(y_test, test_preds)\n",
    "    r2 = r2_score(y_test, test_preds)\n",
    "    \n",
    "    print(f\"{key} Test 성능\")\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n",
    "    print(\"R-Squared:\", r2)\n",
    "    \n",
    "    ## Test 성능 저장\n",
    "    # 운영 시 -> '기준일자', '기준주차' 컬럼 필요\n",
    "    eval_df = pd.DataFrame({'Frpd_latcnm': [frpd_latcnm],\n",
    "                            'Model_Name':['Price Prediction - XGBRegressor'],\n",
    "                            'Model_Object' :[best_model],\n",
    "                            'MSE':[mse],\n",
    "                            'RMSE':[rmse],\n",
    "                            'MAE':[mae],\n",
    "                            'MAPE':[mape]})\n",
    "    \n",
    "    eval_df_all.append(eval_df)\n",
    "    \n",
    "    ##############################################################################\n",
    "    # Train 성능\n",
    "    train_preds = best_model.predict(X_train)\n",
    "\n",
    "    mse = mean_squared_error(y_train, train_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_train, train_preds)\n",
    "    mape = mean_absolute_percentage_error(y_train, train_preds)\n",
    "    r2 = r2_score(y_train, train_preds)\n",
    "\n",
    "    print(f\"{key} Train 성능\")\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n",
    "    print(\"R-Squared:\", r2)\n",
    "    \n",
    "    ##############################################################################\n",
    "    ## 변수 중요도 저장\n",
    "    # 운영 시 -> '기준일자', '기준주차' 컬럼 필요\n",
    "    importance_data  = []\n",
    "    feature_names = list(X_train.columns)\n",
    "    for i, model in enumerate(best_model.estimators_):\n",
    "        importance = model.feature_importances_\n",
    "        ranked_features = np.argsort(importance)[::-1] #중요도 내림차순 정렬 후 인덱스 반환\n",
    "        for rank, j in enumerate(ranked_features):\n",
    "            importance_data.append([frpd_latcnm, 'Price Prediction - XGBRegressor',\n",
    "                                    f\"Model {i+1}\", rank+1, feature_names[j], importance[j]])\n",
    "\n",
    "    columns = ['Frpd_latcnm', 'Model_Name', 'Model_Num', 'Rank', 'Feature', 'Importance']\n",
    "    importance_df = pd.DataFrame(importance_data, columns = columns)\n",
    "    importance_df_all.append(importance_df)\n",
    "    \n",
    "    ##############################################################################\n",
    "    ## 시각화를 위한 실제값/예측값 저장    \n",
    "    # 실제값\n",
    "    y_averaged_columns = [y_test.iloc[:, i:i+6].mean(axis=1) for i in range(0, len(y_test.columns), 6)]\n",
    "    y_test_week = pd.concat(y_averaged_columns, axis=1).reset_index(drop = True)\n",
    "    new_column = {0: '실제값 - 1주차', 1: '실제값 - 2주차', 2: '실제값 - 3주차', 3: '실제값 - 4주차'}\n",
    "    y_test_week.rename(columns = new_column, inplace = True)\n",
    "    \n",
    "    # 예측값\n",
    "    test_preds = pd.DataFrame(test_preds)\n",
    "    pred_averaged_columns = [test_preds.iloc[:, i:i+6].mean(axis=1) for i in range(0, len(test_preds.columns), 6)]\n",
    "    pred_week = pd.concat(pred_averaged_columns, axis=1).reset_index(drop = True)\n",
    "    new_column = {0: '예측값 - 1주차', 1: '예측값 - 2주차', 2: '예측값 - 3주차', 3: '예측값 - 4주차'}\n",
    "    pred_week.rename(columns = new_column, inplace = True)\n",
    "    \n",
    "    date_df = test_tmp[['bas_dt', 'bas_ym', 'bas_week']].reset_index(drop = True)\n",
    "    results = pd.concat([date_df, y_test_week.iloc[:,0], pred_week.iloc[:,0], y_test_week.iloc[:,1], pred_week.iloc[:,1], \n",
    "                         y_test_week.iloc[:,2], pred_week.iloc[:,2], y_test_week.iloc[:,3], pred_week.iloc[:,3]], axis = 1)\n",
    "    \n",
    "    results_all.append(results)\n",
    "    \n",
    "    ##############################################################################\n",
    "    ## 모델 저장\n",
    "    model_name = f\"{key}_2년.pkl\"\n",
    "    with open(model_name, 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    print(f\"{key} model saved.\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"{key} 실행시간: {execution_time}초\")\n",
    "    print('==='*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능지표\n",
    "eval_potato = eval_df_all[0]\n",
    "eval_leak = eval_df_all[1]\n",
    "eval_radish = eval_df_all[2]\n",
    "eval_cabbage = eval_df_all[3]\n",
    "eval_apple = eval_df_all[4]\n",
    "eval_pepper = eval_df_all[5]\n",
    "\n",
    "# 변수 중요도\n",
    "importance_potato = importance_df_all[0]\n",
    "importance_leak = importance_df_all[1]\n",
    "importance_radish = importance_df_all[2]\n",
    "importance_cabbage = importance_df_all[3]\n",
    "importance_apple = importance_df_all[4]\n",
    "importance_pepper = importance_df_all[5]\n",
    "\n",
    "# 모델 결과\n",
    "results_potato = results_all[0]\n",
    "results_leak = results_all[1]\n",
    "results_radish = results_all[2]\n",
    "results_cabbage = results_all[3]\n",
    "results_apple = results_all[4]\n",
    "results_pepper = results_all[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = {'Potato':results_potato, 'Leak':results_leak, 'Radish':results_radish,\n",
    "          'Cabbage':results_cabbage, 'Apple':results_apple, 'Pepper':results_pepper}\n",
    "\n",
    "for key, value in result.items():\n",
    "    for i in range(1, 5):\n",
    "        plt.figure(figsize=(20, 6))\n",
    "        plt.plot(value[f\"실제값 - {i}주차\"], label = 'Original Data', color = 'blue')\n",
    "        plt.plot(value[f\"예측값 - {i}주차\"], label = 'Predicted Data', color = 'red')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Price')\n",
    "        plt.xticks(range(0, 52), value['bas_dt'])\n",
    "        plt.title(f\"{key} Week {i} Prediction\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
